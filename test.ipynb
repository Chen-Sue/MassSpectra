{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "mol = Chem.MolFromSmiles('CS(=O)CCCCCCCN=C=S')\n",
    "mol = Chem.MolFromSmiles('Coc1cc(CCN)c(OC)cc1Br')\n",
    "Draw.MolToImage(mol, size=(150,150), kekulize=True)\n",
    "# Draw.ShowMol(mol, size=(150,150), kekulize=False)\n",
    "Draw.MolToFile(mol, 'data/output.png', size=(600, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "smis=[\n",
    "    'COC1=C(C=CC(=C1)NS(=O)(=O)C)C2=CN=CN3C2=CC=C3',\n",
    "    'C1=CC2=C(C(=C1)C3=CN=CN4C3=CC=C4)ON=C2C5=CC=C(C=C5)F',\n",
    "    'COC(=O)C1=CC2=CC=CN2C=N1',\n",
    "    'C1=C2C=C(N=CN2C(=C1)Cl)C(=O)O',\n",
    "]\n",
    "template = Chem.MolFromSmiles('c1nccc2n1ccc2')\n",
    "AllChem.Compute2DCoords(template)\n",
    "mols=[]\n",
    "for smi in smis:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    AllChem.GenerateDepictionMatching2DStructure(mol,template)\n",
    "    mols.append(mol)\n",
    "img=Draw.MolsToGridImage(mols,molsPerRow=4,subImgSize=(200,200),legends=['' for x in mols])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C(=O)CC(Br)C[N+]CN\n",
      "C ( = O ) C C ( Br ) C [ N + ] C N\n",
      "True\n",
      "C o c 1 c c ( C C N ) c ( O C ) c c 1 Br\n",
      "O [ C @@ H ] 1 C [ C @@ ] ( O ) ( C [ C @@ H ] ( O ) [ C @ H ] 1 O C ( = O ) \\ C = C \\ C 1 = C C ( O ) = C ( O ) C = C 1 ) C ( O ) = O\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils_function import split_smiles\n",
    "def test_split():\n",
    "    sm = 'C(=O)CC(Br)C[N+]CN'\n",
    "    pred = 'C ( = O ) C C ( Br ) C [ N + ] C N'\n",
    "    assert split_smiles(sm)==pred\n",
    "    print(sm)\n",
    "    print(pred)\n",
    "    print(split_smiles(sm)==pred)\n",
    "    print(split_smiles(\"Coc1cc(CCN)c(OC)cc1Br\"))\n",
    "\n",
    "test_split()\n",
    "\n",
    "print(split_smiles(\"O[C@@H]1C[C@@](O)(C[C@@H](O)[C@H]1OC(=O)\\C=C\\C1=CC(O)=C(O)C=C1)C(O)=O\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "\n",
    "from utils_function import load_data_nmt\n",
    "from prepare_mass_spectra import input_mass_spectra\n",
    "from prepare_smiles import output_smiles\n",
    "from seq_to_seq import Seq2SeqEncoder, Seq2SeqDecoder, train_seq2seq, predict_seq2seq, bleu\n",
    "from transformer import TransformerEncoder, TransformerDecoder\n",
    "import config\n",
    "\n",
    "batch_size = config.batch_size\n",
    "split_ratio = config.split_ratio\n",
    "src_num_steps = config.src_num_steps\n",
    "tgt_num_steps = config.tgt_num_steps\n",
    "embed_size = config.embed_size\n",
    "num_hiddens = config.num_hiddens\n",
    "num_layers = config.num_layers\n",
    "dropout = config.dropout\n",
    "lr = config.lr\n",
    "num_epochs = config.num_epochs\n",
    "split_ratio = config.split_ratio\n",
    "device = config.device\n",
    "\n",
    "tensor_mass_spectra, length_new_mass_spectras, new_mass_spectras = input_mass_spectra()\n",
    "tensor_smiles, smiles = output_smiles()\n",
    "split_train = int(len(new_mass_spectras)*split_ratio)\n",
    "\n",
    "\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(\n",
    "    batch_size=batch_size, source=new_mass_spectras, target=smiles, \n",
    "    src_num_steps=src_num_steps, tgt_num_steps=tgt_num_steps)\n",
    "\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    # print('X:', X.type(torch.int32))\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    # print('X的有效长度:', X_valid_len)\n",
    "    # print('Y:', Y.type(torch.int32))\n",
    "    # print('Y的有效长度:', Y_valid_len)\n",
    "    break\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n",
    "\n",
    "src_test = new_mass_spectras[split_train:]\n",
    "tgt_test = smiles[split_train:]\n",
    "\n",
    "test_iter, src_vocab, tgt_vocab = load_data_nmt(\n",
    "    batch_size=batch_size, source=new_mass_spectras[split_train:], target=smiles[split_train:], \n",
    "    src_num_steps=src_num_steps, tgt_num_steps=tgt_num_steps)\n",
    "\n",
    "for src, tgt in zip(src_test, tgt_test):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, src, src_vocab, tgt_vocab, src_num_steps, tgt_num_steps, device)\n",
    "    print(f'{src} => {translation}, bleu {bleu(translation, tgt, k=2):.3f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8856b389641c5f82c13598162e82c95871ff69e8ef7ec5106d2f60aeab75954"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mass_spectra')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
